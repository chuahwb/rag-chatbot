# RAG Chatbot — sample environment configuration
# Copy this file to `.env` and fill in the placeholders as needed.

# -----------------------------------------------------------------------------
# Core LLM / API providers
# -----------------------------------------------------------------------------

# Primary OpenAI project key used by:
# - Planner LLM (intent/slots/decision/synthesis)
# - Embeddings for products RAG
# - Outlets Text2SQL (when TEXT2SQL_PROVIDER=openai)
OPENAI_API_KEY=sk-your-openai-key-here

# Planner + LLMs
PLANNER_LLM_PROVIDER=openai        # openai | fake | local
PLANNER_MODEL=gpt-4.1-mini
PLANNER_TEMPERATURE=0.1
PLANNER_MAX_CALLS_PER_TURN=4

# -----------------------------------------------------------------------------
# Calculator tool
# -----------------------------------------------------------------------------

# Use in-process calculator by default for local/dev (no extra service needed).
CALC_TOOL_MODE=local               # local | http

# When CALC_TOOL_MODE=http, point to your external calculator service:
# CALC_HTTP_BASE_URL=http://localhost:9000
# CALC_HTTP_TIMEOUT_SEC=5

# -----------------------------------------------------------------------------
# Products RAG (drinkware FAISS index)
# -----------------------------------------------------------------------------

# Embedding provider for product documents.
EMBEDDINGS_PROVIDER=openai         # openai | fake

# Vector store backend for drinkware products.
PRODUCT_VECTOR_STORE_BACKEND=faiss # faiss | pinecone

# Path to FAISS index directory (inside Docker container).
VECTOR_STORE_PATH=/app/data/faiss/products

# Pinecone configuration (only used when PRODUCT_VECTOR_STORE_BACKEND=pinecone).
# PINECONE_API_KEY=your-pinecone-api-key
# PINECONE_INDEX_NAME=zus-products
# PINECONE_CLOUD=aws
# PINECONE_REGION=us-east-1

# Optional product summary generation (AI-written summaries).
PRODUCT_SUMMARY_PROVIDER=openai    # none | fake | openai
PRODUCT_SUMMARY_MODEL=gpt-4.1-mini
PRODUCT_SUMMARY_TIMEOUT_SEC=8

# -----------------------------------------------------------------------------
# Outlets Text2SQL (SQLite + LLM-generated SQL)
# -----------------------------------------------------------------------------

# Provider for NL→SQL:
# - openai: use OpenAI ChatCompletion
# - local: use Ollama (OLLAMA_HOST) if running
# - fake: deterministic heuristic generator (no external calls)
TEXT2SQL_PROVIDER=openai           # openai | local | fake
TEXT2SQL_MODEL=gpt-4.1-mini
TEXT2SQL_TIMEOUT_SEC=8

# Outlets DB backend + URLs.
# - For local/dev keep SQLite (default below).
# - For Supabase/Postgres set OUTLETS_DB_BACKEND=postgres and provide OUTLETS_POSTGRES_URL.
OUTLETS_DB_BACKEND=sqlite        # sqlite | postgres
OUTLETS_SQLITE_URL=sqlite:////app/data/sqlite/outlets.db
# Legacy fallback (if OUTLETS_SQLITE_URL unset):
# SQLITE_URL=sqlite:///./data/sqlite/outlets.db
# Example Supabase DSN (requires psycopg driver):
# OUTLETS_DB_BACKEND=postgres
# OUTLETS_POSTGRES_URL=postgresql+psycopg://USER:PASSWORD@db.supabase.co:5432/postgres

# Optional local Ollama endpoint when TEXT2SQL_PROVIDER=local
OLLAMA_HOST=http://localhost:11434

# -----------------------------------------------------------------------------
# Service behavior / CORS / SSE
# -----------------------------------------------------------------------------

# Enable Server-Sent Events for planner telemetry (/events).
ENABLE_SSE=true

# Allowed frontend origins (React dev server, etc.).
# Either a JSON array as below or a comma-separated string is fine.
CORS_ORIGINS=["http://localhost:5173"]
# Deployed frontend origin (Render static site).
RENDER_FRONTEND_ORIGIN=https://rag-chatbot-web.onrender.com

# -----------------------------------------------------------------------------
# Langfuse observability (optional)
# -----------------------------------------------------------------------------
# When set, Langfuse will receive traces for planner and LLM calls.

LANGFUSE_PUBLIC_KEY=pk-lf-your-public-key
LANGFUSE_SECRET_KEY=sk-lf-your-secret-key
LANGFUSE_HOST=https://cloud.langfuse.com
LANGFUSE_RELEASE=local             # e.g. git SHA, version tag, or "local"